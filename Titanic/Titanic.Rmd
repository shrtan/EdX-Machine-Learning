---
title: "Titanic"
output:
  pdf_document: default
  html_document: default
---

```{r cars}
library(titanic)    # loads titanic_train data frame
library(caret)
library(tidyverse)
library(rpart)
# 3 significant digits
options(digits = 3)
# Clean the data
titanic_clean <- titanic_train %>%
  mutate(Survived = factor(Survived),
         Embarked = factor(Embarked),
         Age = ifelse(is.na(Age), median(Age, na.rm = TRUE), Age), # NA age to median age
         FamilySize = SibSp + Parch + 1) %>%    # count family members
  select(Survived,  Sex, Pclass, Age, Fare, SibSp, Parch, FamilySize, Embarked)
```


1. Training and Test sets: Use the caret package to create a 20% data partition based on the Survived column. Assign the 20% partition to test_set and the remaining 80% partition to train_set.
```{r}
test_index <- createDataPartition(titanic_clean$Survived, times = 1, p = 0.2, list = FALSE)
test <- titanic_clean[test_index,]
train <- titanic_clean[-test_index,]
```


2. Baseline Prediction by Guessing the Outcome: The simplest prediction method is randomly guessing the outcome without using additional predictors. These methods will help determine whether the machine learning algorithm performs better than chance.
```{r}
guess_pred <- sample(c(0, 1), size = nrow(test), replace = TRUE)
#accuracy of this guessing method
mean(guess_pred == test$Survived)
```

3. Predicting Survival by Sex
```{r}
library(broom)
#a. Use the training set to determine whether members of a given sex were more likely to survive or die. 
train %>%
  group_by(Sex) %>%
  summarize(Survived = mean(Survived == 1))
#b. Predict survival using sex on the test set: if the survival rate for a sex is over 0.5, predict survival for all individuals of that sex, and predict death if the survival rate for a sex is under 0.5.
sex_model <- train %>%
  group_by(Sex) %>%
  summarize(Survived_predict = ifelse(mean(Survived == 1) > 0.5, 1, 0))
test_set1 <- test %>%
  inner_join(sex_model, by = 'Sex')
cm1 <- confusionMatrix(data = factor(test_set1$Survived_predict), reference = factor(test_set1$Survived))
cm1 %>% tidy() %>% filter(term == "accuracy")
```


4. Predicting survival by Passenger Class
```{r}
pclass_model <- train %>%
  group_by(Pclass) %>%
  summarize(Survived_predict = ifelse(mean(Survived == 1) > 0.5, 1, 0))
test_set2 <- test %>%
  inner_join(pclass_model, by = 'Pclass')
cm2 <- confusionMatrix(data = factor(test_set2$Survived_predict), reference = factor(test_set2$Survived))
cm2 %>% tidy() %>% 
  filter(term == 'accuracy')
```

Use the training set to group passengers by both sex and passenger class. Which sex and class combinations were more likely to survive than die (i.e. >50% survival)?
```{r}
combined_model <- train %>%
  group_by(Pclass, Sex) %>%
  summarize(Survived_predict = ifelse(mean(Survived == 1) > 0.5, 1, 0))
test_set3 <- test %>%
  inner_join(combined_model, by = c('Pclass', 'Sex'))
cm3 <- confusionMatrix(data = factor(test_set3$Survived_predict), reference = factor(test_set3$Survived))
cm3 %>% tidy() %>% 
  filter(term == 'accuracy')
```


5. Confusion Matrix: create confusion matrices for the combined sex and class model and inspect sensitivity, specificity and balanced accuracy.
```{r}
cm3 %>% tidy() %>% 
  filter(term == 'sensitivity' | term == 'specificity' | term == 'balanced_accuracy') 
```


6. Calculate  scores for the sex model, class model, and combined sex and class model.
```{r}
F_meas(data = factor(test_set1$Survived_predict), reference = factor(test_set1$Survived))
F_meas(data = factor(test_set2$Survived_predict), reference = factor(test_set2$Survived))
F_meas(data = factor(test_set3$Survived_predict), reference = factor(test_set3$Survived))
```

7. Survival by Fare - LDA and QDA
```{r}
#Train a model using linear discriminant analysis (LDA)
fit_lda <- train(Survived ~ Fare, data=train, method = 'lda')
survived_hat <- predict(fit_lda, test)
#accuracy
mean(survived_hat == test$Survived)
#qda model
fit_qda <- train(Survived ~ Fare, data=train, method = 'qda')
survived_hat <- predict(fit_qda, test)
#accuracy
mean(survived_hat == test$Survived)
```


8. Logistic Regression Models
```{r}
#Train a logistic regression model using age as the only predictor
fit_sex <- glm(Survived ~ Sex, data=train, family = binomial)
survived_hat <- predict(fit_sex, test)
survived_hat <- ifelse(survived_hat >= 0, 1, 0)
mean(survived_hat == test$Survived)
#Train a logistic regression model using all predictors
fit_all <- glm(Survived ~ ., data=train, family = binomial)
survived_hat <- predict(fit_all, test, type = "response")
survived_hat <- ifelse(survived_hat >= 0.5, 1, 0)
mean(survived_hat == test$Survived)
```


9.kNN model
```{r}
#tuning model with k = seq(3, 51, 2)
k <- seq(3, 51, 2)
fit_knn <- train(Survived ~ ., data = train, method = "knn", tuneGrid = data.frame(k))
fit_knn$bestTune
#plotting k values
ggplot(fit_knn)
#of 7, 11, 17 and 21, which yields the highest accuracy
fit_knn$results %>% filter(k %in% c(7, 11, 17, 21)) %>% pull(Accuracy)
#accuracy
survived_hat <- predict(fit_knn, test)
mean(survived_hat == test$Survived)
```


10. Cross-Validation: Instead of the default training control, use 10-fold cross-validation where each partition consists of 10% of the total.
```{r}
#tuning model with k = seq(3, 51, 2)
control <- trainControl(method = "cv", number = 10, p = .9) 
train_knn_cv <- train(Survived ~ ., method = "knn",  
                      data = train, 
                      tuneGrid = data.frame(k = seq(3, 51, 2)), 
                      trControl = control) 
#optimal value of k
train_knn_cv$bestTune
#accuracy of test set
survived_hat <- predict(train_knn_cv, test)
mean(survived_hat == test$Survived)
```


11. Classification Tree Model 
a) Tune the complexity parameter with cp = seq(0, 0.05, 0.002)
```{r}
fit_tree <- train(Survived ~ ., method = "rpart",  
                  data = train, 
                  tuneGrid = data.frame(cp = seq(0, 0.05, 0.002))) 
fit_tree$bestTune
fit_tree$results
#accuracy with test set
survived_hat <- predict(fit_tree, test)
mean(survived_hat == test$Survived)
```

b. Inspect the final model and plot the decision tree.
```{r}
library(rpart.plot)
rpart.plot(fit_tree$finalModel, type = 3, box.palette = c("red", "green"), fallen.leaves = TRUE) 
```


12. Random Forest Model
```{r}
#Test values of mtry = seq(1:7) 
#Set ntree to 100
fit_rf <- train(Survived ~ ., data = train, method = "rf",
                tuneGrid = data.frame(mtry = seq(1:7)), ntree = 100)
fit_rf$bestTune
#accuracy
survived_hat <- predict(fit_rf, test)
confusionMatrix(data = factor(survived_hat), reference = factor(test$Survived))
mean(survived_hat == test$Survived)
#determine the importance of various predictors to the random forest model
varImp(fit_rf$finalModel)
```